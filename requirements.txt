# TODO When updating flash-attn or torch in the future, make sure to update the version in the Dockerfile 
torch<=2.3.0
scipy
packaging
sentencepiece
datasets
deepspeed
accelerate==0.31.0
# peft>=0.11.1
peft
bitsandbytes>=0.41.1
evaluate>=0.4.0
tokenizers==0.19.1
protobuf
transformers==4.40.2
openai>=1.0.0
tiktoken
rouge_score
tensorboard
wandb
gradio>=3.50.2
termcolor
jsonlines
unidic-lite
einops
flash-attn==2.5.8 # should really only be in dockerfile. Local env often doesn't have GPUs
fire
alpaca-eval==0.6.2
# for human eval web app
flask
# Newer vLLM requires pydantic >= 2, but deepspeed requires pydantic < 2
# if we are not using olmo models, this is fine.
# once https://github.com/microsoft/DeepSpeed/pull/5167 is merged, we can
# update vLLM and remove the need for a separate olmo inference file
vllm>=0.4.1
openpyxl
# for ifeval
nltk
langdetect
immutabledict
# for math evaluations
antlr4-python3-runtime==4.11.0
mpmath==1.3.0
sympy==1.12.0
datasets
six
urllib3
idna
certifi
pyyaml

# flash-attn==2.5.8 --no-build-isolation
# bitsandbytes

# pip uninstall torch torchvision torchaudio
# pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html

# pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121 ##解决gpu not found问题
# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
# conda install -c conda-forge accelerate
# conda update -c conda-forge transformers
    
    
# export PATH="/home/azureuser/.local/bin:$PATH" ##
# echo $PATH


# source ~/.bashrc
# nano ~/.bashrc
# cat ~/.bashrc

# echo $PATH
# export PATH="$HOME/.local/bin:$PATH"  >> ~/.bashrc


#####################################################################
# '''New instance'''
#####################################################################
# export PATH="/home/azureuser/.local/bin:$PATH"  >> ~/.bashrc
# pip3 install deepspeed accelerate datasets transformers==4.40.2 bitsandbytes peft SentencePiece
# pip install --upgrade protobuf

# bash ./scripts/finetune_with_accelerate.sh


# pip install transformers==4.36.2

# azcopy copy ./data_refine/ 'https://afminternshipuksouth.blob.core.windows.net/jinlong?sp=racwdlmeop&st=2024-07-25T22:34:10Z&se=2024-07-26T06:34:10Z&sv=2022-11-02&sr=c&sig=Lqw62TgCXvKzMHW5lZybuUJWOuFRIUAIdGlAvZQPQww%3D' --recursive