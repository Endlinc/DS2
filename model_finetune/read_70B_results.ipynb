{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Average Acc]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import fire\n",
    "'''\n",
    "{baseline_tag: \n",
    "    { \n",
    "        eval_dataset:{ }\n",
    "                        \n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "root_result_path = '../finetune_70B_results'\n",
    "train_dataset='all_train'\n",
    "base_model = \"meta-llama/Meta-Llama-3-70B\"\n",
    "\n",
    "labeling_models = [\"meta-llama/Meta-Llama-3.1-8B-Instruct\", \"gpt-4o-mini\", \"mistralai/Mistral-7B-Instruct-v0.3\"]\n",
    "\n",
    "eval_dataset_lists = ['mmlu', 'truthfulqa', 'gsm', 'bbh', 'tydiqa']\n",
    "\n",
    "all_results = {}  \n",
    "cur_results = {}\n",
    "\n",
    "# Load results from JSON files\n",
    "for labeling_model in labeling_models:\n",
    "    all_results[labeling_model] = {}\n",
    "    cur_results[labeling_model] = {}\n",
    "    if 'llama' in labeling_model:\n",
    "        # baseline_tags=['random',  'completion', 'perplexity',  'knn', 'less', 'full', 'label-filtered', 'diversity-filtered',  'filtered', 'filtered-cured-0.4'] #baselines\n",
    "        baseline_tags=['label-filtered', 'diversity-filtered',  'filtered', 'filtered-cured-0.4'] #baselines\n",
    "\n",
    "    elif 'gpt' in labeling_model:\n",
    "        baseline_tags = ['label-filtered', 'diversity-filtered', 'filtered-cured-0.5']\n",
    "    elif 'mistral' in labeling_model:\n",
    "        baseline_tags = ['label-filtered', 'diversity-filtered', 'filtered-cured-0.5']\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    for tag in baseline_tags:\n",
    "        baseline_results = {}\n",
    "        for eval_dataset in eval_dataset_lists:\n",
    "            path = f'{root_result_path}/{labeling_model}/{train_dataset}/{eval_dataset}/{base_model}/{tag}/metrics.json'\n",
    "            try:\n",
    "                with open(path, 'r') as f:\n",
    "                    json_file = json.load(f)\n",
    "                baseline_results[eval_dataset] = json_file\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Failed to find the file at {path}\")\n",
    "                baseline_results[eval_dataset] = None\n",
    "        \n",
    "        all_results[labeling_model][tag] = baseline_results\n",
    "\n",
    "    # Extract relevant metrics and store in a DataFrame\n",
    "    for tag in baseline_tags:\n",
    "        baseline_result = []\n",
    "        for eval_dataset in eval_dataset_lists:\n",
    "            if all_results[labeling_model][tag][eval_dataset] is None:\n",
    "                value = 0\n",
    "            else:\n",
    "                if eval_dataset == 'mmlu':\n",
    "                    value = round(all_results[labeling_model][tag][eval_dataset]['average_acc'] * 100, 1)\n",
    "                elif eval_dataset == 'bbh':\n",
    "                    value = round(all_results[labeling_model][tag][eval_dataset]['average_exact_match']* 100, 1)\n",
    "                elif eval_dataset == 'tydiqa':\n",
    "                    value = round(all_results[labeling_model][tag][eval_dataset]['average']['f1'], 1)\n",
    "                elif eval_dataset == 'gsm':\n",
    "                    value = round(all_results[labeling_model][tag][eval_dataset]['exact_match']* 100, 1)\n",
    "                elif eval_dataset == 'truthfulqa':\n",
    "                    # value = round(all_results[labeling_model][tag][eval_dataset][\"truth-info acc\"]* 100, 1)\n",
    "                    value = round(all_results[labeling_model][tag][eval_dataset][\"MC2\"]* 100, 1)\n",
    "                else:\n",
    "                    print(\"unknown eval dat·aset!\")\n",
    "\n",
    "\n",
    "            baseline_result.append(value)\n",
    "        cur_results[labeling_model][tag] = baseline_result\n",
    "\n",
    "# 构建 DataFrame\n",
    "df_results = pd.DataFrame(cur_results, columns=['Labeling Model', 'Baseline Tag', 'Evaluation Dataset', 'Value'])\n",
    "\n",
    "# 将 `Evaluation Dataset` 列作为列名，重构 DataFrame\n",
    "df_pivot = df_results.pivot(index=['Labeling Model', 'Baseline Tag'], columns='Evaluation Dataset', values='Value')\n",
    "\n",
    "# 计算平均值\n",
    "df_pivot['Average Acc'] = df_pivot.mean(axis=1).round(1)\n",
    "\n",
    "# 确保显示完整表格\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(df_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Labeling Model        Baseline Tag  mmlu  truthfulqa   gsm   bbh  tydiqa  Average Acc\n",
      "0   meta-llama/Meta-Llama-3.1-8B-Instruct          completion  67.1        44.6  85.0  80.0    32.7         61.9\n",
      "1   meta-llama/Meta-Llama-3.1-8B-Instruct          perplexity  67.1        45.7  82.5  79.4    31.9         61.3\n",
      "2   meta-llama/Meta-Llama-3.1-8B-Instruct                 knn  66.1        46.8  79.5  81.2    34.5         61.6\n",
      "3   meta-llama/Meta-Llama-3.1-8B-Instruct              random  66.9        45.3  82.5  79.4    30.3         60.9\n",
      "4   meta-llama/Meta-Llama-3.1-8B-Instruct                less  66.6        43.9  83.5  81.0    34.1         61.8\n",
      "5   meta-llama/Meta-Llama-3.1-8B-Instruct      label-filtered  66.4        44.9  85.0  78.7    31.4         61.3\n",
      "6   meta-llama/Meta-Llama-3.1-8B-Instruct  diversity-filtered  66.6        45.1  87.0  80.0    31.4         62.0\n",
      "7   meta-llama/Meta-Llama-3.1-8B-Instruct            filtered  66.2        46.8  84.0  79.2    33.8         62.0\n",
      "8   meta-llama/Meta-Llama-3.1-8B-Instruct  filtered-cured-0.4  66.3        45.7  84.5  81.5    32.0         62.0\n",
      "9                             gpt-4o-mini      label-filtered  66.7        46.5  85.5  81.3    30.9         62.2\n",
      "10                            gpt-4o-mini  diversity-filtered  66.1        45.4  85.0  81.4    32.9         62.2\n",
      "11                            gpt-4o-mini            filtered  66.7        46.4  88.0  79.2    33.2         62.7\n",
      "12                            gpt-4o-mini  filtered-cured-0.5  66.6        43.4  87.0  80.9    34.3         62.4\n",
      "13     mistralai/Mistral-7B-Instruct-v0.3      label-filtered  66.8        43.3  87.0  80.3    31.6         61.8\n",
      "14     mistralai/Mistral-7B-Instruct-v0.3  diversity-filtered  67.5        47.8  85.0  82.1    33.5         63.2\n",
      "15     mistralai/Mistral-7B-Instruct-v0.3            filtered  66.2        45.3  84.5  79.0    33.6         61.7\n",
      "16     mistralai/Mistral-7B-Instruct-v0.3  filtered-cured-0.5  67.1        45.5  85.5  81.1    36.1         63.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 定义路径和输入数据\n",
    "root_result_path = '../finetune_70B_results'\n",
    "train_dataset = 'all_train'\n",
    "base_model = \"meta-llama/Meta-Llama-3-70B\"\n",
    "\n",
    "labeling_models = [\"meta-llama/Meta-Llama-3.1-8B-Instruct\", \"gpt-4o-mini\", \"mistralai/Mistral-7B-Instruct-v0.3\"]\n",
    "eval_dataset_lists = ['mmlu', 'truthfulqa', 'gsm', 'bbh', 'tydiqa']\n",
    "\n",
    "all_results = []  # 用于存储所有结果行\n",
    "\n",
    "# 遍历模型和标签，加载 JSON 文件数据\n",
    "for labeling_model in labeling_models:\n",
    "    if 'llama' in labeling_model:\n",
    "        baseline_tags = [ 'completion', 'perplexity', 'knn', 'random', 'less', 'label-filtered', 'diversity-filtered', 'filtered', 'filtered-cured-0.4']\n",
    "    elif 'gpt' in labeling_model:\n",
    "        baseline_tags = ['label-filtered', 'diversity-filtered', 'filtered', 'filtered-cured-0.5']\n",
    "    elif 'mistral' in labeling_model:\n",
    "        baseline_tags = ['label-filtered', 'diversity-filtered', 'filtered', 'filtered-cured-0.5']\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    for tag in baseline_tags:\n",
    "        row = {'Labeling Model': labeling_model, 'Baseline Tag': tag}\n",
    "        for eval_dataset in eval_dataset_lists:\n",
    "            path = f'{root_result_path}/{labeling_model}/{train_dataset}/{eval_dataset}/{base_model}/{tag}/metrics.json'\n",
    "            try:\n",
    "                with open(path, 'r') as f:\n",
    "                    json_file = json.load(f)\n",
    "                # 提取不同数据集的指标值\n",
    "                if eval_dataset == 'mmlu':\n",
    "                    value = round(json_file.get('average_acc', 0) * 100, 1)\n",
    "                elif eval_dataset == 'bbh':\n",
    "                    value = round(json_file.get('average_exact_match', 0) * 100, 1)\n",
    "                elif eval_dataset == 'tydiqa':\n",
    "                    value = round(json_file.get('average', {}).get('f1', 0), 1)\n",
    "                elif eval_dataset == 'gsm':\n",
    "                    value = round(json_file.get('exact_match', 0) * 100, 1)\n",
    "                elif eval_dataset == 'truthfulqa':\n",
    "                    # value = round(json_file.get('truth-info acc', 0) * 100, 1)\n",
    "                    value = round(json_file.get('MC2', 0) * 100, 1)\n",
    "\n",
    "                else:\n",
    "                    value = 0\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Failed to find the file at {path}\")\n",
    "                value = 0\n",
    "            row[eval_dataset] = value\n",
    "        all_results.append(row)\n",
    "\n",
    "# 构建 DataFrame\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "# 计算每个行的平均准确率\n",
    "df_results['Average Acc'] = df_results[eval_dataset_lists].mean(axis=1).round(1)\n",
    "\n",
    "# 确保显示完整表格\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# 打印 DataFrame\n",
    "print(df_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
