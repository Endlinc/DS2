{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label curation \n",
    "\n",
    "- First Step to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_909303/224999676.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  reports = torch.load(report_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cured sample size: 32123\n",
      "Corrupted samples total: 158013\n",
      "Original Counter(labels): Counter({3: 116114, 4: 57669, 2: 48254, 1: 47402, 0: 27386, 5: 4107})\n",
      "counting revised label size: 32123\n",
      "Label size: 300932\n",
      "Revised Counter(labels): Counter({3: 139351, 4: 55491, 1: 42337, 2: 38460, 0: 22580, 5: 2713})\n",
      "Label-wise filter out samples: 158013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_909303/224999676.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  labels = torch.load(root_path + \"output_labels_revised.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from collections import Counter\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "seed =3\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "dataset_name='all_train'\n",
    "model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\" ###confidence_prob = 0.4\n",
    "# model_name=\"gpt-4o-mini\" #####confidence_prob = 0.5\n",
    "# model_name= \"mistralai/Mistral-7B-Instruct-v0.3\" #######confidence_prob = 0.5\n",
    "\n",
    "confidence_prob = 0.4\n",
    "dataset_size = 40000\n",
    "\n",
    "\n",
    "# all_train_dataset = load_dataset('json', data_files =f\"./data/train_data/{dataset_name}_data.jsonl\")\n",
    "all_train_dataset = load_dataset('json', data_files =f\"../{dataset_name}_dataset.json\")\n",
    "\n",
    "#################################################################################################################################\n",
    "# label curation reports\n",
    "# report_path = f\"score_curation/results/{model_name}/{dataset_name}/{dataset_name}_report.pt\"\n",
    "\n",
    "report_path = f\"./results-embedding-model-bge/{model_name}/{dataset_name}/{dataset_name}_report.pt\"\n",
    "\n",
    "\n",
    "\n",
    "reports = torch.load(report_path)\n",
    "\n",
    "# Part 1 (label-wise): label curation\n",
    "corrupted_samples = [x[0] for x in reports.detection['label_error']]\n",
    "\n",
    "cured_samples = []\n",
    "cured_sample_labels = []\n",
    "for sample in reports.curation['label_curation']:  # (idx, label, confidence)\n",
    "    if sample[2] >= confidence_prob:  # confidence prob\n",
    "        cured_samples.append(sample[0])\n",
    "        cured_sample_labels.append((sample[0], sample[1]))\n",
    "\n",
    "print(f\"Cured sample size: {len(cured_sample_labels)}\")\n",
    "\n",
    "# Filter out some cured samples from corrupted instances\n",
    "cured_samples_set = set(cured_samples)\n",
    "corrupted_samples_total = [x for x in corrupted_samples if x not in cured_samples_set]\n",
    "\n",
    "print(f\"Corrupted samples total: {len(corrupted_samples_total)}\")\n",
    "\n",
    "# Change the original labels to the suggested label\n",
    "root_path = f\"../model_finetune/selected_data/{model_name}/{dataset_name}/\"\n",
    "\n",
    "\n",
    "labels = torch.load(root_path + \"output_labels_revised.pt\")\n",
    "\n",
    "print(f\"Original Counter(labels): {Counter(labels)}\")\n",
    "\n",
    "count=0\n",
    "count_labels_5 = []\n",
    "count_labels_4 = []\n",
    "count_labels_3 = []\n",
    "count_labels_2 = []\n",
    "\n",
    "for sample_label in cured_sample_labels:\n",
    "    if labels[sample_label[0]] == 5:\n",
    "        count_labels_5.append(sample_label[1])\n",
    "        # continue ## determine whether remain the 5-rated samples\n",
    "\n",
    "    if labels[sample_label[0]] == 4:\n",
    "        count_labels_4.append(sample_label[1])\n",
    "\n",
    "    if labels[sample_label[0]] == 3:\n",
    "        count_labels_3.append(sample_label[1])\n",
    "\n",
    "    if labels[sample_label[0]] == 2:\n",
    "        count_labels_2.append(sample_label[1])\n",
    "\n",
    "    labels[sample_label[0]] = sample_label[1]\n",
    "    count+=1\n",
    "\n",
    "print(f\"counting revised label size: {count}\")\n",
    "\n",
    "print(f\"Label size: {len(labels)}\")\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "print(f\"Revised Counter(labels): {label_counts}\")\n",
    "\n",
    "# Filter out the low-quality samples\n",
    "label_wise_filter_out_samples = set(corrupted_samples_total)\n",
    "print(f\"Label-wise filter out samples: {len(label_wise_filter_out_samples)}\")\n",
    "\n",
    "### load the label noise \n",
    "\n",
    "# torch.save(labels, root_path + f\"output_labels_revised_cured.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 8, 4: 57})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(count_labels_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 2538, 2: 84, 1: 8})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(count_labels_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 1416, 1: 28, 2: 402})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(count_labels_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 269, 3: 2952, 1: 32})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(count_labels_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filetered method: Our data selection method\n",
    "-  Filtered 5: label-filtered based: all 5 samples  + 4-rated samples select using sorted long-tail score (reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the remaining samples with high quality: 300932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished caching labels indices...\n",
      "Size of the filtered dataset: 422\n",
      "Size of the filtered dataset: 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 31.53ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6225106"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 3\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Part 2 (feature-wise): Process rare samples\n",
    "# Filter top 50% rare samples based on list in 'reports'\n",
    "rare_samples = reports.detection['rare_example'][:len(reports.detection['rare_example']) // 2]\n",
    "rare_samples_filtered = np.array(rare_samples)[:, :2]  # Retain only the first two columns (index and score)\n",
    "\n",
    "print(f\"Size of the remaining samples with high quality: {len(rare_samples_filtered)}\")\n",
    "\n",
    "# Convert 'labels' list to NumPy array for efficient indexing\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Cache indices for each label value to avoid repeated calculations\n",
    "label_indices_cache = {label: np.where(labels == label)[0] for label in [5, 4, 3, 2, 1]}\n",
    "print(f\"Finished caching labels indices...\")\n",
    "\n",
    "# Initialize list to store selected indices\n",
    "filtered_indices = []\n",
    "\n",
    "# Filter and sort samples by label, prioritizing high-quality samples\n",
    "for target_label in [5, 4, 3, 2, 1]:\n",
    "    if len(filtered_indices) >= dataset_size:\n",
    "        break\n",
    "\n",
    "    # Retrieve indices for the current label from the cache\n",
    "    label_indices = label_indices_cache[target_label]\n",
    "    available_size = dataset_size - len(filtered_indices)\n",
    "\n",
    "    # Add all label indices if there is enough space, else add only top samples\n",
    "    if available_size > len(label_indices):\n",
    "        filtered_indices.extend(label_indices.tolist())\n",
    "    else:\n",
    "        # Filter rare samples for the current label\n",
    "        label_samples = rare_samples_filtered[np.isin(rare_samples_filtered[:, 0], label_indices)]\n",
    "        if len(label_samples) > 0:  # Ensure label_samples is not empty\n",
    "            # Sort samples by score in descending order and select top samples\n",
    "            sorted_samples = label_samples[label_samples[:, 1].argsort()[::-1]][:available_size]\n",
    "            filtered_indices.extend(sorted_samples[:, 0].astype(int).tolist())\n",
    "\n",
    "    print(\"Size of the filtered dataset:\", len(filtered_indices))\n",
    "\n",
    "# Load the dataset and filter out invalid samples\n",
    "data = load_dataset('json', data_files=root_path + 'full_dataset.json')\n",
    "\n",
    "# Select samples based on filtered indices and save as JSON\n",
    "filtered_dialogs = data['train'].select(filtered_indices)\n",
    "filtered_dialogs.to_json(root_path + f\"filtered-cured-{confidence_prob}-{dataset_size // 1000}k_dataset.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
